{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4573c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import sqlite3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bc70d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "# used to create id strings later\n",
    "base_url = 'https://www.basketball-reference.com'\n",
    "\n",
    "season_gamecount = 1\n",
    "\n",
    "precovid_seasons = ['0304','0405', '0506', '0607', '0708','0809', '0910', '1011', '1112', '1213']\n",
    "precovid_url_years = ['2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013']\n",
    "\n",
    "# used to create sql database table columns\n",
    "info_columns = ['game_id', 'season', 'date', 'away_team', 'away_score', 'home_team', 'home_score', 'result']\n",
    "num_columns = ['FG', 'FGA', '3P', '3PA', 'FT', 'FTA', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', '+/-',\n",
    "               'FG%', '3P%', 'FT%', 'TS%', 'eFG%', '3PAr', 'FTr', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'ORtg', 'DRtg', 'BPM']\n",
    "# pause between each server call\n",
    "delay = time.sleep(np.random.randint(3,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39beb188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_game_info(url, season_id, season_gamecount):\n",
    "    \n",
    "    game_count = str(season_gamecount)\n",
    "    while len(game_count) < 4:\n",
    "        game_count = '0' + game_count\n",
    "    \n",
    "    id_string = url.strip(string.ascii_letters+string.punctuation)\n",
    "    year = id_string[0:4]\n",
    "    month = id_string[4:6]\n",
    "    day = id_string[6:8]\n",
    "    \n",
    "    date = year+'-'+month+'-'+day\n",
    "    \n",
    "    game_id = int(season_id+month+day+game_count)\n",
    "    season_id = int(season_id)\n",
    "    \n",
    "    return [game_id, season_id, date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7282e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_team_info(table):\n",
    "    '''\n",
    "    Create a dataframe with game results. Uses an html table as input.\n",
    "    \n",
    "    ---\n",
    "    Inputs:\n",
    "    \n",
    "    table: a BeautifulSoup html table\n",
    "    ---\n",
    "    Outputs:\n",
    "    \n",
    "    team_info: a dataframe with the relevant game information (team_ids, scores, and boolean 'results' column)\n",
    "    '''\n",
    "    \n",
    "    # get team_ids\n",
    "    id_rows = table.findAll('th', attrs={'class':'center', 'data-stat':'team', 'scope':'row'})\n",
    "    team_ids = [row.text.strip() for row in id_rows]\n",
    "    \n",
    "    # get final score\n",
    "    scores = table.findAll('td', attrs={'class': 'center', 'data-stat': 'T'})\n",
    "    final_scores = [int(score.text.strip()) for score in scores]\n",
    "    \n",
    "    # boolean game-winner: away=0, home=1\n",
    "    if final_scores[0] > final_scores[1]:\n",
    "        result=0\n",
    "    else:\n",
    "        result=1\n",
    "    \n",
    "    team_info = [team_ids[0], final_scores[0], team_ids[1], final_scores[1], result]\n",
    "    \n",
    "    return team_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f70f4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_info_df(game_info, team_info, info_columns):\n",
    "    info = game_info + team_info\n",
    "    info_df = pd.DataFrame([info], columns=info_columns)\n",
    "    return info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b59cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boxscores(table, game_id):\n",
    "\n",
    "    # ignore first 'tr', it is table title, not column\n",
    "    rows = table.findAll('tr')[1:]\n",
    "    # first 'th' is 'Starters', but will be changed into the player names\n",
    "    headers = rows[0].findAll('th')\n",
    "    # provide column names\n",
    "    headerlist = [h.text.strip() for h in headers]\n",
    "    \n",
    "    # ignore first row (headers)\n",
    "    data = rows[1:]\n",
    "    # get names column\n",
    "    player_names = [row.find('th').text.strip() for row in rows]\n",
    "    # get player stats\n",
    "    player_stats = [[stat.text.strip() for stat in row.findAll('td')] for row in data]\n",
    "    # add player name as first entry in each row\n",
    "    for i in range(len(player_stats)):\n",
    "        # ignore header with i+1\n",
    "        player_stats[i].insert(0, player_names[i+1])\n",
    "    \n",
    "    # create player stats dataframe\n",
    "    player_box_df = pd.DataFrame(player_stats, columns=headerlist)\n",
    "    # drop 'Reserves' row\n",
    "    player_box_df.drop(player_box_df[player_box_df['Starters'] == 'Reserves'].index, inplace=True)\n",
    "    \n",
    "    # add game id column\n",
    "    player_box_df.insert(loc=0, column='game_id', value=game_id)\n",
    "    \n",
    "    # create team stats dataframe from last row in player stats\n",
    "    team_box_df = pd.DataFrame(player_box_df.iloc[-1]).T\n",
    "    \n",
    "    #drop team totals from player stats df\n",
    "    player_box_df = player_box_df[:-1].rename(columns={'Starters': 'player'})\n",
    "\n",
    "    return player_box_df, team_box_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1a4f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_boxscores(boxscore_list, team_ids, scope):\n",
    "\n",
    "    # create tuple for every 2 boxscores in list\n",
    "    pairs = [((boxscore_list[i]), (boxscore_list[i + 1])) for i in range(0, len(boxscore_list), 2)]\n",
    "    \n",
    "    clean_boxscores= []\n",
    "    \n",
    "    for pair in pairs:\n",
    "        \n",
    "        # combine regular and adv boxscores\n",
    "        df = pd.concat([*pair], axis=1)\n",
    "        # drop columns with duplicate names\n",
    "        df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "        \n",
    "        clean_boxscores.append(df)\n",
    "    \n",
    "    for i in range(len(clean_boxscores)):\n",
    "        \n",
    "        if scope=='team':\n",
    "            clean_boxscores[i].rename(columns={'Starters': 'team'}, inplace=True)\n",
    "            clean_boxscores[i]['team'] = team_ids[i]\n",
    "            \n",
    "        elif scope=='player':\n",
    "            clean_boxscores[i].insert(loc=2, column='team', value=team_ids[i])\n",
    "    \n",
    "    return clean_boxscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd88af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dtypes(df, num_columns):\n",
    "\n",
    "    df.replace(to_replace='', value='-99', inplace=True)\n",
    "    \n",
    "    for column in num_columns:\n",
    "        df[column] = df[column].astype('float64')\n",
    "        \n",
    "    df.replace(to_replace=-99, value=np.nan, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92223d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_PIE(player_boxes, totals):\n",
    "    \n",
    "    PIE_denom = (totals['PTS'] + totals['FG'] + totals['FT'] - totals['FGA'] - totals['FTA'] + totals['DRB'] + (0.5*totals['ORB']) + totals['AST'] + totals['STL'] + (0.5*totals['BLK']) - totals['PF'] - totals['TOV'])\n",
    "    player_boxes['PIE'] = round((100 * (player_boxes['PTS'] + player_boxes['FG'] + player_boxes['FT'] - player_boxes['FGA'] - player_boxes['FTA'] + player_boxes['DRB'] + (0.5*player_boxes['ORB']) + player_boxes['AST'] + player_boxes['STL'] + (0.5*player_boxes['BLK']) - player_boxes['PF'] - player_boxes['TOV']) / PIE_denom), 1)\n",
    "    \n",
    "    return player_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54f5f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to sql database\n",
    "conn = sqlite3.connect('NBA-Game-Database-temp')\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3843810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Initialize the WebDriver once at the start\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "for i in range(len(precovid_seasons)):\n",
    "    \n",
    "    season_id = precovid_seasons[i]\n",
    "    season_gamecount = 1\n",
    "    start_url = 'https://www.basketball-reference.com/leagues/NBA_' + precovid_url_years[i] + '_games.html'\n",
    "    \n",
    "    # Open the season schedule page\n",
    "    driver.get(start_url)\n",
    "    time.sleep(2)  # delay to wait for page load\n",
    "    src = driver.page_source\n",
    "    \n",
    "    # Create BeautifulSoup object from the page source\n",
    "    parser = BeautifulSoup(src, 'lxml')\n",
    "    \n",
    "    # Every month from the season\n",
    "    months = parser.find('div', attrs={'class': 'filter'})\n",
    "    \n",
    "    if not months:\n",
    "        print(f\"Months filter not found for season {season_id}. Skipping this season.\")\n",
    "        continue\n",
    "    \n",
    "    # Partial URLs for each month\n",
    "    links = months.findAll('a')\n",
    "    month_links = [base_url + link['href'] for link in links]\n",
    "    # Only include regular season months (Oct-Apr)\n",
    "    month_links = month_links[0:7]\n",
    "    \n",
    "    for month_url in month_links:\n",
    "        \n",
    "        # Navigate to the month URL\n",
    "        driver.get(month_url)\n",
    "        time.sleep(2)  # delay to wait for page load\n",
    "        \n",
    "        src = driver.page_source\n",
    "        parser = BeautifulSoup(src, 'lxml')\n",
    "        table = parser.find('div', attrs={'class': 'table_container is_setup'})\n",
    "        \n",
    "        if not table:\n",
    "            print(f\"Table container not found at {month_url}. Skipping this month.\")\n",
    "            continue\n",
    "        \n",
    "        # Check if final month (Apr). If true, set limit for game URLs before playoffs start\n",
    "        row_num = None\n",
    "        splits = table.findAll('tr', attrs={'class': 'thead'})\n",
    "        \n",
    "        for split in splits:\n",
    "            if 'Playoffs' in split.text:\n",
    "                row_num = int(split['data-row'])\n",
    "                \n",
    "        # Get partial URLs of every game in the month (if Apr, stop before playoffs)\n",
    "        if row_num is None:\n",
    "            game_partial_urls = table.findAll('td', attrs={'class': 'center', 'data-stat': 'box_score_text'})\n",
    "        else:\n",
    "            game_partial_urls = table.findAll('td', attrs={'class': 'center', 'data-stat': 'box_score_text'}, limit=row_num)\n",
    "        \n",
    "        game_urls = [base_url + url.a['href'] for url in game_partial_urls]\n",
    "        \n",
    "        # Open every game URL, retrieve and manipulate data, add to SQL database\n",
    "        for game_url in game_urls:\n",
    "    \n",
    "            driver.get(game_url)\n",
    "            time.sleep(2)  # delay to wait for page load\n",
    "            src = driver.page_source\n",
    "            parser = BeautifulSoup(src, 'lxml')\n",
    "            \n",
    "            # Game info database:\n",
    "            id_table = parser.find('table', attrs={'class': 'suppress_all stats_table', 'id': 'line_score'})\n",
    "            \n",
    "            if not id_table:\n",
    "                print(f\"Line score table not found at {game_url}. Skipping this game.\")\n",
    "                continue\n",
    "            \n",
    "            game_info = create_game_info(url=game_url,\n",
    "                                         season_id=season_id,\n",
    "                                         season_gamecount=season_gamecount)\n",
    "            # Will use game_id with create_boxscores()\n",
    "            game_id = game_info[0]\n",
    "            team_info = create_team_info(id_table)\n",
    "            # Will use team_ids with merge_boxscores()\n",
    "            team_ids = [team_info[0], team_info[2]]\n",
    "            \n",
    "            info_df = create_info_df(game_info=game_info,\n",
    "                                     team_info=team_info,\n",
    "                                     info_columns=info_columns)\n",
    "            # Write game info to SQL database\n",
    "            info_df.to_sql('game_info', con=conn, if_exists='append', index=False)\n",
    "\n",
    "            # Team/player databases:\n",
    "            \n",
    "            # 4 boxscore tables: away_box, away_box_adv, home_box, home_box_adv\n",
    "            stat_tables = parser.findAll('table', attrs={'class': 'sortable stats_table now_sortable'})\n",
    "            \n",
    "            player_box_list = [None, None, None, None]\n",
    "            team_box_list = [None, None, None, None]\n",
    "\n",
    "            # Create team and player boxscores\n",
    "            for idx, stat_table in enumerate(stat_tables):\n",
    "                # Split player and team boxscores\n",
    "                player_box_list[idx], team_box_list[idx] = create_boxscores(stat_table, game_id=game_id)\n",
    "            \n",
    "            # Team stats database:\n",
    "            \n",
    "            # Combine boxscore and advanced boxscore for each team\n",
    "            away_team_box, home_team_box = merge_boxscores(team_box_list, team_ids=team_ids, scope='team')\n",
    "            team_boxes = pd.concat([away_team_box, home_team_box])\n",
    "            team_boxes.reset_index(drop=True, inplace=True)\n",
    "            # Prepare numeric data\n",
    "            team_boxes = change_dtypes(team_boxes, num_columns)\n",
    "            # Write to SQL database\n",
    "            team_boxes.to_sql('team_stats', con=conn, if_exists='append', index=False)\n",
    "            \n",
    "            # Player stats database:\n",
    "            \n",
    "            # Combine boxscore and advanced boxscore for each team\n",
    "            away_player_box, home_player_box = merge_boxscores(player_box_list, team_ids=team_ids, scope='player')\n",
    "            player_boxes = pd.concat([away_player_box, home_player_box])\n",
    "            player_boxes.reset_index(drop=True, inplace=True)\n",
    "            # Prepare numeric data\n",
    "            player_boxes = change_dtypes(player_boxes, num_columns)\n",
    "            # Create team totals for PIE calculation\n",
    "            totals = dict(team_boxes.loc[:, 'FG':'PTS'].sum())\n",
    "            # Add PIE column to player boxscore\n",
    "            player_boxes = create_PIE(player_boxes, totals)\n",
    "            # Write to SQL database\n",
    "            player_boxes.to_sql('player_stats', con=conn, if_exists='append', index=False)\n",
    "\n",
    "            # Increase game count to create next game_id\n",
    "            season_gamecount += 1\n",
    "\n",
    "# Close the browser once all scraping is done\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
